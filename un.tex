\section{Uncomputing and Recomputing}
\subsection{Tock}
The key insight of Zombie is to introduce an abstraction layer between the executing program and the heap. This abstraction layer will allow the heap to transparently discard and recompute the program's intermediate values. To do so, we use the CEK machine to refer to each intermediate value by the index of the computation step that created it. Since each CEK step allocates at most one cell, this correspondence is injective. In other words, instead of storing pointers that refer to memory locations, we will store pointers, which we call ``tocks'', that refer to points in time---that is, CEK step indices.

In our runtime, these ``tocks'' are implemented as 64-bit integers, though in our model we will treat them as logically unbounded integers. There is a global ``current tock'' counter, which starts at 0 and is increased by 1 at every transition step in the abfrsstract machine and every allocation. The cell allocated at step $i$ is then referred to by the tock $i$, and that tock can then be used as a pointer, stored in data structures, looked up by later computations steps, and the like.

Note that, due to the determinism and linearity of the CEK machine, tocks are strictly ordered and the value computed at some tock $i$ can only depend on values computed at earlier tocks. Moreover, we can recreate the value at tock $i$ by merely rerunning the CEK machine from some earlier state to that point. Because the CEK machine is deterministic, this re-execution will produce the same exact value as the original. Because our pointers refer to abstract values, not to specific memory locations, the heap can thus re-compute a value as necessary instead of storing it in memory.

In other words, the way Zombie works is that the heap will store only some of the intermediate values. The ones that aren't stored will instead be recomputed as needed, and the heap will store earlier CEK states to facilitate that. As the program runs, intermediate values can be discarded from the heap to reduce its memory usage.

Because a value can be recomputed from \emph{any} earlier CEK state, it will also turn out to be possible to store relatively few states. Therefore, overall memory usage---for the stored intermediate values and the stored states---can be kept low. In Zombie, we can store asymptotically fewer states than intermediate values, allowing us to asymptotically reduce memory usage.

\subsection{Tock Tree}
In Zombie, the heap is implemented by a runtime data structure called the tock tree. The tock tree maps tocks to the cells allocated by that step; in other words, the tock tree implements the mapping between tocks and their actual memory locations. Because values can be evicted to save memory, however, not all tocks have a mapping in the tock tree. Instead, every tock that \emph{is} present in the tock tree will also store its state. To recompute an evicted value at some tock $i$, the tock tree will find the largest state at tock $j < i$ and replay from that tock to tock $i$.

Each node in the Tock Tree stores both a memory cell and a state. Specifically, consider the execution of the CEK machine from step $t$. In step $t + 1$ it allocates a cell; it then performs a computation in step $t + 2$. So the node at tock $t$ contains both the cell allocated at step $t + 1$ as well as the state \emph{afterward}, at step $t + 2$. A transition might not allocate any new cells, in such a case the Node only stores a state and no memory cell. To be more specific, if the node represents the execution of the CEK machine at step $t$, it will only contain the CEK state at step $t + 1$. Also note that a state, in this context, does not include every info needed for execution: in particular it does not include the tock tree, alongside any data that guide recomputation. More specifically a state denotes either a $\Eval~C~\Env~K~Tock$ or a $\Apply~K~V~Tock$.

One thing worth noticing is that continuations are also reified. This means we treat them as like values, lifting pointers into tock, and storing continuations onto the tock tree. This allows us to also uncompute continuation as well, by evicting the node on the tock tree holding said continuation. This is crucial as traversing a deep data structure non-tail-recursively produces a continuation chain of equal depth. In contrast to a ordinary runtime, in which this is a slight but inevitable unfortunate, in our case, the continuation storage can become the boTleneck of the system.

In order to make this operation efficient, the tock tree is organized as a binary search tree. In a binary search tree, arbitrary keys (tocks) can be looked up in $O(\log(n))$ time, where $n$ is the size of the tock tree, and when a key is not found, the largest key smaller than it can be easily found. Then the heap can replay execution from that point to compute the desired tock.

\begin{figure}
    \begin{tabular}{p{5em} p{3em} p{10em} p{0.45\textwidth}}
        Value & = & \st{P<VCell>} & Tock \\
        Continuation & = & \st{P<KCell>} & Tock \\
        State & ::= & \st{$\Eval~C~\Env~K \mid \Apply~K~V $} & $\Eval~C~\Env~K~Tock \mid \Apply~K~V~Tock $ \\
        RState & ::= & & State | \Return cell \\
        Node & = & & (Maybe(KCell | VCell), State) \\
        Query & $:$ & (TockTree, Tock) & $\rightarrow$ Cell | State \\
        T[t] & = & & Query(T, t) \\
        Insert & $:$ & (TockTree, Tock, Node) & $\rightarrow$ TockTree \\
        Evict & $:$ & (TockTree, Tock) & $\rightarrow$ TockTree \\
    \end{tabular}
    \caption{Tock Tree API.}
\end{figure}
\begin{figure}
    \includegraphics[width=0.5\columnwidth]{img2}
    \caption{a node in the tock tree}
\end{figure}
\begin{figure}
    \includegraphics[width=0.5\columnwidth]{img3}
    \caption{the tock tree with multiple nodes}
\end{figure}

\begin{figure}
    \includegraphics[width=0.5\columnwidth]{img4}
    \caption{lookup failure return the latest earlier node}
\end{figure}

\subsection{Replay Continuation}
When a query to the tock tree fail, meaning that the return node is not an exact match, and therefore does not include the requested tock, replay is needed. However, in order to replay, we need to store the current context, so we know which tock we are looking for, and how to resume after we found said value. We call said information a ReplayContinuation(R). Since replay is recursive, ReplayContinuation form a stack.

The ReplayContinuation store a list of triplet:
\begin{enumerate}
	\item The tock we are looking for
	\item A ReplayFrame, which is a state with a Hole. When the tock is found, it will be plugged into the Hole to continue execution.
	\item The tock to resume to.
\end{enumerate}

\begin{figure}
    \begin{tabular}{p{10em} p{2.6em} p{1em} p{0.45\textwidth}}
        ReplayContinuation & R & ::= & [(Tock, RF, Tock)] \\
        ReplayFrame & RF & ::= & RFLookup V | \\
        & & & RFCase Env N C N C K | \\
        & & & RFZro K | RKFst K | \\
        & & & RFApp Env E K \\
        Replay & R & ::= & (State, R) \\
    \end{tabular}
\end{figure}

\subsection{CEKR Machine}
With the idea of tock, tock tree, and the replay continuation, we can now define an abstract machine, the CEKR Machine, that can uncompute and replay values.

The CEKR Machine consists of 6 parts:
\begin{enumerate}
    \item \textcolor{blue}{C}ontrol, the expression currently being evaluated.
    \item \textcolor{blue}{E}nvironment, a map from the free variables of the Control to their values.
    \item \textcolor{blue}{K}ontinuation, which is to be invoked with the value the Control evaluates to.
    \item \textcolor{blue}{R}eplay, the replay continuation.
    \item The current tock
    \item The tock tree
\end{enumerate}

In addition to the $Eval$ and $Apply$ modes in the CEK machine, there is a $Return$ mode as well. This is an ephemeral mode, indicating that we have found a cell we are replaying for and will start playing from the top of the replay continuation at the next step.

\begin{mathpar}
  \text{Machine} ::= \text{RState}, \text{r}, \text{TockTree}
\end{mathpar}

\subsubsection{PostProcessing}
The CEKR Machine executes by repeatedly computing the next node, and then applying a PostProcess step. the PostProcess step has two responsibilities: it inserts the node onto the tock tree, and checks if the node contains the cell the replay continuation is requesting. If so, it means the current transition has found the cell we are replaying for, and our ending state should be the Return state with said cell. Otherwise, it transits to the original state.

\begin{mathpar}
\inferrule{ }{\CheckReturn: (t, node, r) \rightarrow RState} \and
\inferrule{ }{\CheckReturn(t, (\bot, st), r) = st} \and
\inferrule{t + 1 \neq t'}{\CheckReturn(t, (\_, st), []) = st} \and
\inferrule{ }{\CheckReturn(t, (cell, st), (t + 1, rf):r) = \Return~ cell} \and
\inferrule{t + 1 \neq t'}{\CheckReturn(t, (cell, st), (t', rf):r) = st} \and

\inferrule{ }{\PostProcess: (t, node, r, TockTree) \rightarrow \Machine} \and
\inferrule{ }{\PostProcess(t, node, r, T) = \CheckReturn(t, node, r), r, insert(T, t, node)} \and

\inferrule{ }{ \Machine \leadsto_m Node : Prop } \and
\inferrule{ \Eval(N, \Env, K, t), r, T \leadsto_n node }{ \Eval(N, \Env, K, t), r, T \leadsto \PostProcess(t, node, r, T) } \and
\inferrule{\Apply(K, V, t), r, T \leadsto_n node }{ \Apply(K, V, t), r, T \leadsto \PostProcess(t, node, r, T)} \and
\inferrule{ \Return~ cell, (t, RF, t'):r, T \leadsto_n node }{ Return~ cell, (t, RF, t'):r, T \leadsto PostProcess(t', node, r, T) } \and
\end{mathpar}

The transition is now split into 3 different cases:
\begin{enumerate}
    \item The happy path: in the CEKR machine, looking up from the heap is converted into querying the tock tree. The querying is successful, returning a node with a cell that matches the tock we are querying, and our transition can proceed as normal, producing a node, which is a pair of the cell produced and the state it transits to. PostProcessing is then applied.
    \item The sad path: when querying fails, returning a node that does not contain a matching cell, replay is needed. To replay a cell on tock t, we push the old state alongside t onto the replay continuation, and transit to the state in the node. Note that there is no PostProcessing in this case as a node is not created.
    \item The return path: when the machine enters the $Return$ mode, it indicates that a query once failed, but we found the corresponding cell by replaying. By looking it up from the replay continuation, we can now re-execute the state that failed the query, as if the query result is a node containing said cell. No querying is needed in this case, as there is at most one lookup in each CEK transition, and the corresponding query had just been recomputed. Like the happy path, PostProcessing is needed to insert into the tock tree and to recursively return.
\end{enumerate}

\begin{figure}
\begin{mathpar}
    \inferrule{ }{\Return~ cell, (\_, \RFLookup~ v~ t):r, T \leadsto_n (\bot, \Apply(cell, v, t+1))} \and
    \inferrule{ }{\Return~ (\VLeft X), (\_, \RFCase~ \Env~ LN~ L~ RN~ R~ K~ t):r, T \leadsto_n (\bot, \Eval(L, \Env[LN := X], K, t+1))} \and
    \inferrule{ }{\Return~ (\VRight Y), (\_, \RFCase~ \Env~ LN~ L~ RN~ R~ K~ t):r, T \leadsto_n (\bot, \Eval(R, \Env[RN := Y], K, t+1)) } \and
    \inferrule{ }{\Return~ (\VProd~ X~ Y), (\_, \RFZro~ K~ t):r, T \leadsto_n (\bot, \Apply(K, X, t+1))} \and
    \inferrule{ }{\Return~ (\VProd~ X~ Y), (\_, \RFFst~ K~ t):r, T \leadsto_n (\bot, \Apply(K, Y, t+1))} \and
    \inferrule{ }{\Return~ (\Clos \Env'~ N~ C), (\_, \RFApp~ \Env~ X~ K~ t):r, T \leadsto_n (\KApp_1 \Env' N~ C~ K~, \Eval(X, \Env~, t+1, t+2))} \and   
\end{mathpar}
    \caption{CEKR Transition: Returning}
\end{figure}

\begin{figure}
    \begin{mathpar}
        \inferrule{T[K] = kcell}{\Eval(N, \Env, K, t), r, T \leadsto (\bot, \Apply($kcell$, N, t+1))} \and
        \inferrule{T[K] = st}{\Eval(N, \Env, K, t), r, T \leadsto st, (K, \RFLookup~ N~ t):r, T} \and
        \inferrule{ }{\Eval(\sLet~x=A~\sIn~B, \Env, K, t), r, T \leadsto_n (\KLet~x~K~B~\Env, \Eval(A, \Env, t+1, t+2))} \and
        \inferrule{ }{\Eval(\sLam~N~C, \Env, K, t), r, T \leadsto_n (\Clos~\Env(\text{fv})\cdots N~C, \Eval(X, \Env, t+1, t+2))} \and
        \inferrule{ }{\Eval(\sApp~F~X, \Env, K, t), r, T \leadsto_n (\Eval(X, \Env, t+1, t+2), \KApp_0~\Env~X~K, st) } \and
        \inferrule{ }{\Eval(\sProd~L~R, \Env, K, t), r, T \leadsto_n (\KProd_0~K~R, (\Eval(X, \Env, t+1, t+2) } \and
        \inferrule{ }{\Eval(\sZro~X, \Env, K, t), r, T \leadsto_n (\KZro~K, \Eval(X, \Env, t+1, t+2)) } \and
        \inferrule{ }{\Eval(\sFst~X, \Env, K, t), r, T \leadsto_n (\KFst~K, \Eval(X, \Env, t+1, t+2))} \and
        \inferrule{ }{\Eval(\sLeft~X, \Env, K, t), r, T \leadsto_n (\KLeft~K, \Eval(X, \Env, t+1, t+2)) } \and
        \inferrule{ }{\Eval(\sRight~X, \Env, K, t), r, T \leadsto_n (\KRight~K, \Eval(X, \Env, t+1, t+2))} \and
        \inferrule{ }{\Eval(\sCase~X~\mathit{LN}~L~\mathit{RN}~R, \Env, K, t), r, T \leadsto_n (\KCase~\mathit{LN}~L~\mathit{RN}~R~\Env, \Eval(X, \Env, t+1, t+2) )} \and
    \end{mathpar}
    \caption{CEKR Transition: Eval}
\end{figure}
\begin{figure}
    \begin{mathpar}
        \inferrule{T[K] = st}{\Apply(\KLookup K, V, t), r, T \leadsto st, (K, RFLookup V t):r, T} \and
        \inferrule{T[K] = cell}{\Apply(\KLookup K, V, t), r, T \leadsto_n (\bot, \Apply(cell, V, t+1))} \and
        \inferrule{ }{\Apply(\KLet~ A~ \Env~ C~ K', V, t), r, T \leadsto_n (\bot, \Eval(C, Env[A := V], K', t+1))} \and
        \inferrule{T[V] = st}{Apply(KApp0 Env X K, V, t), r, T \leadsto st, (V, RFApp Env X K t):r, T} \and
        \inferrule{T[V] = \Clos Env' N C }{\Apply(\KApp0~ \Env~ X~ K', V, t), r, T \leadsto_n (KApp1 \Env' N C K', \Eval(X, Env, t+1, t+2))} \and
        \inferrule{ }{\Apply(\KApp1 Env N C K', V, t), r, T \leadsto_n (Nothing, \Eval(C, Env[N := V], K', t+1))} \and
        \inferrule{ }{\Apply(KProd0 Env R K, V, t), r, T \leadsto_n (KProd1 V Env K, \Eval(R, Env, t+1, t+2)) } \and
        \inferrule{ }{\Apply(KProd1 L K, V, t), r, T \leadsto_n (\VProd L V, \Apply(K, t+1, t+2)) } \and
        \inferrule{T[V] = st }{\Apply(KZro K, V, t), r, T \leadsto st, (V, RFZro K t):r, T} \and
        \inferrule{T[V] = VProd X Y }{\Apply(KZro K, V, t), r, T \leadsto_n (\bot, \Apply(K, X, t+1))} \and
        \inferrule{T[V] = st}{\Apply(KFst K, V, t), r, T \leadsto st, (V, RFFst K t):r, T} \and
        \inferrule{T[V] = VProd X Y }{\Apply(KFst K, V, t), r, T \leadsto_n (\bot, \Apply(K, Y, t+1))} \and
    \end{mathpar}
    \caption{CEKR Transition: Apply}
\end{figure}
\begin{figure}
    \begin{mathpar}
        \inferrule{ }{\Apply(KLeft K, V, t), r, T \leadsto_n (VLeft V, \Apply(K, t+1, t+2)) } \and
        \inferrule{ }{\Apply(KRight K, V, t), r, T \leadsto_n (VRight V, \Apply(K, t+1, t+2))} \and
        \inferrule{T[V] = st) \and X \neq V - 1}{\Apply(KCase Env LN L RN R K, V, t), r, T \leadsto st, (V, RFCase Env LN L RN R K t):r, T} \and
        \inferrule{T[V] = \VLeft~ X }{\Apply(KCase Env LN L RN R K, V, t), r, T \leadsto_n (\bot, \Eval(L, \Env[LN := X], K', t+1))} \and
        \inferrule{T[V] = \VRight~ Y }{\Apply(KCase Env LN L RN R K, V, t), r, T \leadsto_n (\bot, \Eval(R, \Env[RN := Y], K', t+1))} \and
    \end{mathpar}
    \caption{CEKR Transition: Apply}
\end{figure}


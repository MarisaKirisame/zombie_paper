\section{Plant vs Zombie(8pg)}
\subsection{Insight}

\subsection{Key Idea(1pg)}

There are 3 key insights that enable the above guarantee:
\begin{itemize}
	\item A global clock increasing on return/bind invocation. This not only give a way to quickly detect same objects for hashconsing, but as opposed to classical hash consing, the key itself have semantic meaning: < denote happens-before.
	\item Recomputing A also recompute what is inside A. This mean we can forget about some inner thunk, as long as we can redirect the pointers to such thunk to an outer thunk. One possibility is to track backpointers and fix them, but this take significantly more time and space. Instead, Track function exit time too. Entering and exiting form a range, and two separate range either form a nested relationship or disjoint relationship. We can then design a datastructure, such that lookup failure return a match one-level above.
\end{itemize}

\todo{this is old tex. merge.}

There are multiple insights that allow us to solve the above 4 problems. Explaining them aid understanding the implementation of Zombie.

0: treat each cell as independent, ignoring all member relationship.
this trivialize size finding.

Zombie allow recursive object, e.g. a list, a tree, or a graph.
For those object, a part of the object can be evicted, and sharing does not affect size counting.
This feature is implemented by ignoring recursiveness. All nesting need to loop through Zombie, and when it does that, the management of subsequent nested Zombie is completely handoff to it.
Note that this allow keeping some value of the list in memory, even when there is previous node evicted!

1: hashconsing. to avoid the same expression producing multiple values, we introduce a type Idx, such that the same trace will be tagged with the same Idx.
Zombie X hold Idx instead of X, and the actual values are stored in a datastructure.
When return x try to create a Zombie X of tag idx, if idx is stored in the datastructure, that value is used instead, even though the computed value is equivalent to said value. This cause x to be immediately unreachable and can be released from memory. This allow evicting most of the list, only keeping some intermediate value. nowhere reachable via the object graph.

2: note that bind can be nested: the function in bind may call more bind. When such nesting occur, executing the higher-level bind will also re-invoke the lower level bind. Hence - it is not necessary to store the lower-level thunk (even though doing so improve performance, as it will execute less code).

With this in mind, if we can create a data structure imitating the bind/return execution of the program, we can remove non top-level nodes, so that lookup will return a higher-level result then the remove node, we solved the breadcrumb problem.
\subsection{Implementation}
Combining the 3 insights above we now sketch an implementation of Zombie.
There is a global tock, which value begin from 0, increasing on every invocation of bind/return.
A Zombie<X> hold an Integer, tock, instead of value of type X.
The value is stored in the tock tree.
Whenever a call to return or bind is finished, we put a Node onto the tock tree.
The range of said node is the tock value at the begin and end of the invocation.

For return, the node contain the value.

For bind, the node contain the list of input Zombie, the output Zombie, and the function pointer.

In bind, we have to force values from Zombie X to X. This is done via looking it up from the tock tree. If the look up node is not a Value, but the Thunk, we need to rewind the tock to the beginning of said thunk, replay the value, get the value from the tock tree (todo: avoid infinite loop here), and restore the tock.

\section{Tock Tree API}
we need a data structure, such that when after removing a node, looking said node up does not return Nothing, but rather return a less precise answer.

Below is an API summing up what we need.

Tock = u64

Range = Tock * Tock

Make: TockTree X

Insert: TockTree X -> Range * X -> ()

Per two call to Insert, their range must either be nested or non-overlapping.

Lookup: TockTree X -> Tock -> Option (Range * X)

Remove: TockTree X -> Range -> ()

geometric series
\subsection{Tock Tree}
Such data structure is implemented by a tree, where the tree structures mimic that of bind/return nesting structure. In particular, each node in the tock tree X have:
a range
children, stored in an avl-tree, ordered by their start-tock. The range of the children do not overlap.
X

The top level node is special in that it does not have range nor children. Or, put in another way, we have a Tock-forest.

Given an AVL of node ordered by their start-tock, we can test if a tock X is in one of the node's range by finding the largest node smaller or equal to X, then seeing if said node include X. using this operation, we can implement all operations on tock-tree in a straightforward manner.

The key of the datastructure is the Lookup Function, which recursively traverse down the tree, until it found a node such that it's children does not the tock. In such case we return the last range and the value. This setup allow removing node, without LookUp returning None, as it will return the value higher-up instead. As the higher up function semantically imply, and will recreate all lower up function, removing will not destroy any information (in the information theoretic sense).
\subsection{Recomputation}
upon a get, one might find a Recomputer instead of a Value on the tock tree. When that happend, we push the tock of get to a 'request stack', then replay the function.

said replaying begin by rebinding (which might cause further replay), then executing the function. since we already know the exact tock we want, when encountering bind which cannot possibly include such tock (the function is already on the tock tree, and it's range does not include X), we are free to skip such function, returning the stored return zombie instead. upon replaying the exact tock, we replace the tock on the request stack, with the value (crucially, not the zombie) return is invoked with.

note how the normal evaluation is eager as we have to assign tock to all function, but replay evaluation is lazy as we are free to skip once the metadata is present. This is a sad consequence of relying on tock.

\subsection{formalization}
\subsubsection{language}

\begin{mathpar}
    E := BaseTerm | Var | Abs (Var:T)... E | App E E... | Bind E... E | Return E

	T := BaseType | Z T | T... ~> T
\end{mathpar}

\todo{STLC is weak, but I want to say that it is 'the same' under another type system. or better yet, despite the monadic structure type is inessential to our approach}

\subsubsection{typing rule}
\begin{mathpar}
	\inferrule{ }{Env |- BaseTerm : BaseType}
	
	\inferrule{v:T in Env}{Env |- v : T}

	\inferrule{Var:T... |- E : T}{Env |- Abs (Var:T)... E : T... ~> T}
	
	\inferrule{Env |- E : T... -> T \\ (Env |- E : T)...}{Env |- App E E... : T}
	
	\inferrule{(Env |- E : T)... \\ Env |- E : (E:T)... ~> T}{Bind E... E : T}
	\inferrule{Env |- E : T}{Env |- Return E : Z T}
\end{mathpar}
note that in the Abs rule, and the Bind rule, we throw away the old environment. this is because we do not allow closure. One could still implement another type representing closure or defunctionalized closure, different from the ~> type bindN need.
\subsubsection{small step operational semantic}
\begin{mathpar}
	V ::= BaseTerm | Abs ... E | Z N

	\inferrule
	{v=V in Env}
	{Env, H, v ~>> Env, H, V}
	
	\inferrule
	{Env, H, E ~>> Env', H', E'}
	{Env, H, App E E... ~>> Env, App E' E...}
	
	\inferrule
	{Env, H, E. ~>> Env, H', E.'}
	{Env, H, App V (V...)E.(E...) ~>> Env, H', App V (V...)E.'(E...)}
	
	\inferrule
	{ }
	{Env, H, App ((Var:T)...E) V... ~>> (Var=V)..., H, E}

	\inferrule
	{Env, H, E. ~>> Env', H', E.'}
	{Env, Bind (V...)E.(E...) E ~>> Env, H', Bind (V...)E'(E...) E}
	
	\inferrule
	{Env, H, E ~>> Env', H', E'}
	{Env, Bind V... E ~>> Env, H', Bind V... E'}

	\inferrule
	{}
	{Env, Bind Z V... (Var:T)... E ~>> (Var:V)..., E}

	\inferrule
	{Env, H, E ~>> Env', H', E'}
	{Env, H, Return E ~>> Env, H', E'}

	\inferrule
	{ }
	{Env, H, Return V ~>> Env, H(x := V), Z x}
\end{mathpar}
\todo{write about tock tree}
one weird thing about it is that our 'small step semantic' may actually take multiple step. 
This allow us to isolate out small step semantic, simplifying our correctness proofs. If wished, one could define some classical small step semantic, and prove bisimulation between the two.

another thing is that Env modification does not carry. \todo{I think this is normal. check.}

also - a bit unsettling that Abs Evaluate the Function before the Argument, but Bind does it the other way. Should we unify the two, or make Bind look more like app?
\subsection{Correctness Gurantee}
\subsubsection{Progress}
\subsubsection{Preservation}
\subsection{Asymptotic}
\subsection{not violating information theory}
clearly, it is impossible to store information in 0-bits, so where and how much storage are we using to store the breadcrumbs?

as the program execute, the global tock counter will continuously increase, until it reach the 64-bit limit and overflow.

assume there is x live objects, and y dead objects, word size needed to store tock per live object is O(log(x + y)), so total memory size is O(x * log(x + y)) taking the derivative of the expression w.r.t. y, give O(x/(x + y)). this give a sub-constant result: as there are more and more breadcrumb, the cost of storing each of them decrease, approaching 0!

in practice, this number will not overflow. even in some extreme case where it does, making it into 128-bit will guarantee non-overflowness by being longer then the age of the universe. Even at 128-bit, the word size is still a small portion of the total overhead.

suprsingly, this 'reducing n space program into log n space program' is also seen in the famous TREEVERSE. it is unclear if this is a mere conincidence, or if there is any deeper connection.
\subsection{OLD}
All Zombies are threaded through a logical clock, a tock, stored as a u64.
During execution, the clock increases whenever makeZombie and bindZombie are called.

A Zombie contains, theoretically speaking, contains only the tock that the Zombie is created at.
To access the actual value of the Zombie, a ZombieNode, we rely on a global data structure.
It will be explained later.
(We also store a weakpointer to ZombieNode as a cache, to quicken access. This is just a cache, and is irrelevant to the rest of Zombie).
A ZombieNode holds X but is inherited from the Object class, which contain a virtual destructor and nothing else. This essentially allow one to type erase ZombieNode of different type, to put them into the same data structure.

We implement Zombie via two global data structures, a log and a pool.
The pool track all currently in-memory Zombie representation - it manage space
The log record actions taken used for recomputation - it manage time

The pool holds a vector of uniqueptr<Phantom>, the class that manage eviction.
It has api to evict objects, and api to score the profitability of eviction.
When we are low on memory, we can find a value in this vector, call evict(), and remove it.
This will free up memory in the log.

For every call to makeZombie and bindZombie, we keep track of when the function is called vs when the function exited. This establishes a tock range. 
For makeZombie, since it does not call any more functions, its interval length is 1, containing exactly the tock of the zombie.
Tock range overlap iff one contain another, iff one function calls another function. We then store tock range, paired with information on said function. 
For makeZombie we store a shared pointer to the ZombieNode. 
For bindZombie, we record the function used to compute it, as std::function<void(const std::vector<const void*>)>, alongside the tocks of all input Zombies, and the tock of output Zombie. We call it a Rematerializer. The input argument is type erased to void*, as Zombie is type polymorphic, but we need a type uniform interface here.

The log is some kind of interval tree. Each node in the tree stores its begin and end interval, alongside a value, and a BST from tock to sub nodes. The key of BST is the start of the sub nodeâ€™s interval. When we query the log via a tock, we will find a value with the closest interval containing said tock. This mean, we might query for a Zombie, but instead of getting a ZombieNode, we get a Rematerializer.
In such a case, we replay the Rematerializer by fetching the ZombieNode from the tock (replaying recursively if necessary), setting the clock to begin of the function temporarily, and entering said function. Afterward we set the clock back, and fetch the value from a tree.
When we set the clock via rematerialization, we always set it to a smaller value, thus guaranteeing termination.

The log itself, when replaying, also serve as a memo table, indexed by tock. When we want to create a Zombie, we will skip when such Zombie already exist in the log. When we want to run BindZombie, we return the result tock when the precise Rematerializer exist in the log. This allow us to not compute the same function multiple time, if we know its result, and allow us to not store the same Zombie multiple time.

Note that all non-top-levels node in the tree can be removed. When we do so, we will free up memory, and when we need the value again, we can always replay a node higher up.

This design allow us to store n log n amount of metadata per n alive(nonevicted) objects.

Thus, when a Rematerializer dominate no value, and another value dominate Rematerializer, we remove it. (todo: implement). Idea: manage this using pool.

There is a slight error with the above design: maybe the value is recomputed and put on the tree, but then evicted, and fetch will not return a ZombieNode but a Rematerializer. To fix this we introduce a global data structure called Tardis, consist of a tock and a shared ptr<ZombieNode>*. When we create Zombie, when the tock match that of tardis, it will write to the shared ptr, holding the value longer.

\subsection{replaying semantic}
Program evaluate differently in replaying mode then in non-replay mode, as relevant Node might already be on the tock tree. When 

Every entering tock (lhs of a range) uniquely identify a return/bind.

% see https://www.khoury.northeastern.edu/home/wand/csg264/latex/mathpartir/mathpartir.pdf

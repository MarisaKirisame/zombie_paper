%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmsmall')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
\usepackage{mathpartir}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
	\providecommand\BibTeX{{%
			Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}


%%
%% These commands are for a JOURNAL article.
\acmJournal{JACM}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\usepackage{xcolor}
\usepackage{mdframed}
\newcommand\todo[1]{\textcolor{red}{#1}}
\newcommand\pavel{\todo{pavel look here} }
\newcommand\tablewidth{25em}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}
	%%
	%% The "title" command has an optional parameter,
	%% allowing the author to define a "short title" to be used in page headers.
	\title{Uncomputation}
	%%
	%% The "author" command and its associated commands are used to define
	%% the authors and their affiliations.
	%% Of note is the shared affiliation of the first two authors, and the
	%% "authornote" and "authornotemark" commands
	%% used to denote shared contribution to the research.
	\author{Maisa Kirisame}
	\email{marisa@cs.utah.edu}
	\orcid{1234-5678-9012}
	\authornotemark[1]
	\affiliation{%
		\institution{University of Utah}
		\streetaddress{P.O. Box 1212}
		\city{Salt Lake City}
		\state{Utah}
		\country{USA}
		\postcode{43017-6221}
	}

	\author{Pavel Panchekha}
	\email{}
	\orcid{1234-5678-9012}
	\authornotemark[1]
	\affiliation{%
		\institution{University of Utah}
		\streetaddress{P.O. Box 1212}
		\city{Salt Lake City}
		\state{Utah}
		\country{USA}
		\postcode{43017-6221}
	}
	
	%%
	%% By default, the full list of authors will be used in the page
	%% headers. Often, this list is too long, and will overlap
	%% other information printed in the page headers. This command allows
	%% the author to define a more concise list
	%% of authors' names for this purpose.
	\renewcommand{\shortauthors}{Kirisame et al.}
	%%
	%% The abstract is a short summary of the work to be presented in the
	%% article.
	\begin{abstract}
		Program execution need memory. Program may run out of memory for multiple reasons: big dataset, exploding intermediate state, the machine have less memory than others, etc. When this happens, the program either get killed, or the operating system swaps, significantly degrading the performance.
		We propose a technique, uncomputation, that allow the program to continue running gracefully even after breaching the memory limit, without significant performance degradation.
		Uncomputation work by turning computed values back into thunk, and upon re-requesting the thunk, computing and storing them back.
		A naive implementation of uncomputation will face multiple problems. Among them, the most crucial and the most challenging one is that of breadcrumb. After a value is uncomputed, it's memory can be released but some memory, breadcrumb, is needed, so we can recompute the value back.
		Ironically, in a applicative language, due to boxing all values are small. This mean uncomputation, implemented naively, will only consume more memory, defeating the purpose.
		We present a runtime system, implemented as a library, that is absolved of the above breadcrumb problem, seemingly storing recompute information in 0-bits and violating information theory.
	\end{abstract}
	
	%%
	%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
	%% Please copy and paste the code instead of the example below.
	%%
		
	%%
	%% Keywords. The author(s) should pick words that accurately describe
	%% the work being presented. Separate the keywords with commas.
	\keywords{Do, Not, Us, This, Code, Put, the, Correct, Terms, for,
		Your, Paper}
	
	\received{20 February 2007}
	\received[revised]{12 March 2009}
	\received[accepted]{5 June 2009}
	
	%%
	%% This command processes the author and affiliation and title
	%% information and builds the first part of the formatted document.
	\maketitle
	\section{Intro}
	\section{Overview}	
	FIGURE draw attention to KEY IDEA

explain argument
key steps
dependency between steps
focus on the dependency

Section: Tocks (5pg long)
tock: exploit linear property of CEK machine
talk about time instead of memory
mapping stored in an ordered tree
Context (not a section)
map is sparse
lookup fail, need to recompute
also store CEK context

Section: The CEKR Machine (???)
Replay Stack
the section with lots of greeks
argue about progress

Section: Implementation (3pg long)
Heuristic
Loop Unrolling

Key question: How to get the replay stack small?
Key question: Garbage Collection/Eager Eviction

Summarize the meeting into key step

Sad Path

Replay Stack

Double O(1)

Quality


Another kind of thing in tock tree.

Transition from X -> Y

Allocated during the transition

Map from tock to Cell | Context

\section{Core Language}	
Zombie works on a untyped, purely functional, call by value language. Program in the language is then executed by the CEK abstract machine.

We had deliberately chosen to represent our semantic by the CEK machine, as it have two crucial property:

\begin{enumerate}
	\item It is linear. An execution of a program can be characterized as a (possibly infinite) sequence the abstract machine transit through.

	\item Each step take a small, bounded amount of work, and especially for lookup/alloc.
\end{enumerate}

\begin{enumerate}
	\item Note how our implementation is different from a CEK Machine: In particular, we had made pointer and pointer lookup explicit, as we later have to abstract over and reason over them. 
\end{enumerate}

Section: CEK Machine: pointers, lookup, allocate substeps (2.5-3pg long)
Figure: draw on whiteboard, take screenshot.
	
Below we sketch out the language and the cek machine. Note that this is the standard semantic - there is neither uncomputation nor replaying present. Uncomputation will be represented independently afterward.
	\begin{figure}
	\begin{tabular}{lllp{\tablewidth}}
	Name & $N$ & $::=$ & A set of distinct names \\
	Expr & $E$ & $::=$ & $N\mid \text{Let}\ N\ E\ E\ \mid \text{Lam}\ N\ E\ \mid \text{App}\ E\ E\ \mid$ \\
	& & & $ \text{Prod}\ E\ E\ \mid \text{Zro}\ E\ \mid \text{Fst}\ E\ \mid $ \\
	& & & $ \text{Left}\ E\mid\text{Right}\ E\mid \text{Case}\ E\ N\ E\ N\ E $ \\
	\end{tabular}
	\caption{The source language}
	\end{figure}

	\begin{figure}
	\begin{tabular}{lllp{\tablewidth}}
	Heap & $H$ & $::=$ & An abstract key value store \\
	Pointer<X> & P<X> & $::=$ & Key into heap with value type X \\
	Alloc & & : & (X, H) -> (Pointer<X>, H) \\
	Lookup & & : & (Pointer<X>, H) -> X \\
	\end{tabular}
	\caption{Heap API}
	\end{figure}
	\begin{figure}
	\begin{tabular}{lllp{\tablewidth}}
		Continuation & K & $::=$ & P<KCell> \\

		KCell & & $::=$ & Stop | KLet N Env E K | KApp0 Env E K | KApp1 V K | \\
		& & & KProd0 Env E K | KProd1 V K | KZro K | KFst K | \\
		& & & KLeft K | KRight K | KCase Env N E N E K \\
		
		Value & V & ::= & P<VCell> \\
		VCell & & ::= & Clos Env N E | VProd V V | VLeft V | VRight V \\
		
		Environment & Env & ::= & (N, V)\dots \\
		State & & ::= & Step Expr Env K | Apply K V \\
	\end{tabular}
	\caption{Definitions for the CEK Machine}
	\end{figure}
	\begin{mdframed}
		\[
		\inferrule{ }{\text{State}, \text{Heap} \leadsto \text{State}, \text{Heap}}
		\]
		\[
		\inferrule{ }{\text{Step}(\text{N}, \text{Env}, \text{K}), \text{H} \leadsto \text{Apply}(\text{K}, \text{Env}(\text{N})), \text{H}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KLeft}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Left}\ \text{X}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KRight}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Right}\ \text{X}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KProd0}\ \text{K}\ \text{R}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Prod}\ \text{L}\ \text{R}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{L}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KZro}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Zro}\ \text{X}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KFst}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Fst}\ \text{X}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KCase}\ \text{LN}\ \text{L}\ \text{RN}\ \text{R}\ \text{Env}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Case}\ \text{X}\ \text{LN}\ \text{L}\ \text{RN}\ \text{R}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KLet}\ \text{A}\ \text{K}\ \text{C}\ \text{Env}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Let}\ \text{A}\ \text{B}\ \text{C}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{B}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{KApp0}\ \text{K}\ \text{X}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{App}\ \text{F}\ \text{X}, \text{Env}, \text{K}), \text{H} \leadsto \text{Step}(\text{F}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Alloc}(\text{Clos}\ \text{Env}(\text{fv})\dots \text{N}\ \text{E}, \text{H}) = (\text{P}, \text{H'})}{\text{Step}(\text{Lam}\ \text{N}\ \text{E}, \text{Env}, \text{K}), \text{H} \leadsto \text{Apply}(\text{K}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KLeft}\ \text{K} \\ \text{Alloc}(\text{VLeft}\ \text{V}, \text{H}) = (\text{P}, \text{H'})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KRight}\ \text{K} \\ \text{Alloc}(\text{VRight}\ \text{V}, \text{H}) = (\text{P}, \text{H'})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KCase}\ \text{Env}\ \text{LN}\ \text{L}\ \text{RN}\ \text{R}\ \text{K} \\ \text{Lookup}(\text{V}, \text{H}) = \text{VLeft}\ \text{V}}{\text{Apply}(\text{P}, \text{V}) \leadsto \text{Step}(\text{L}, \text{Env}(\text{LN} := \text{V}), \text{K})}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KCase}\ \text{Env}\ \text{LN}\ \text{L}\ \text{RN}\ \text{R}\ \text{K} \\ \text{Lookup}(\text{V}, \text{H}) = \text{VRight}\ \text{V}}{\text{Apply}(\text{P}, \text{V}) \leadsto \text{Step}(\text{R}, \text{Env}(\text{RN} := \text{V}), \text{K})}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KProd0}\ \text{Env}\ \text{R}\ \text{K} \\ \text{Alloc}(\text{KProd1}\ \text{V}\ \text{Env}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KProd1}\ \text{L}\ \text{K} \\ \text{Alloc}(\text{VProd}\ \text{L}\ \text{V}, \text{H}) = (\text{P}, \text{H'})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KZro}\ \text{K} \\ \text{Lookup}(\text{V}, \text{H}) = (\text{VProd}\ \text{X}\ \text{Y})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{X}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KFst}\ \text{K} \\ \text{Lookup}(\text{V}, \text{H}) = (\text{VProd}\ \text{X}\ \text{Y})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Apply}(\text{K}, \text{Y}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KLet}\ \text{A}\ \text{Env}\ \text{C}\ \text{K}}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Step}(\text{C}, \text{Env}(\text{A} := \text{V}), \text{K}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KApp0}\ \text{Env}\ \text{X}\ \text{K} \\ \text{Alloc}(\text{KApp1}\ \text{V}\ \text{K}, \text{H}) = (\text{P}, \text{H'})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Step}(\text{X}, \text{Env}, \text{P}), \text{H'}}
		\]
		\[
		\inferrule{\text{Lookup}(\text{P}, \text{H}) = \text{KApp1}\ \text{F}\ \text{K} \\ \text{Lookup}(\text{F}, \text{H}) = (\text{Clos}\ \text{Env}\ \text{N}\ \text{E}, \text{H})}{\text{Apply}(\text{P}, \text{V}), \text{H} \leadsto \text{Step}(\text{E}, \text{Env}(\text{N} := \text{V}), \text{K}), \text{H'}}		
		\]
	\end{mdframed}
	\section{Uncomputing and Recomputing}
	\subsection{Tock}
	Number every step and introduce tock, sitting between memory and program execution
	instead of referring to point in space, refer to point in time.

	Turn pointers of space to pointers of path
	
	\todo{introduce an allocate step. allocation or normal transition advance the tock and get assigned a numbering}
	
	The critical insight of zombie is that multiple abstract machine state compute the same value. To be more precise, if a machine state x step to a machine state y, x must have computed all value that y might compute, and possibly more. This indicate that we do not have to store all previous machine state - some might be dropped in favor of older ones.
	
	For this purpose, we introduced a global, logical time of 64 bit int, a tock. Tock start at 0, and increase by 1 on each transition(step/apply) in the abstract machine, and whenever a value is constructed. Conversely, all tock smaller then the current tock correspond to either a value, or a executed machine state, and vice versa.
	
	More importantly, given a value that correspond to tock X, any machine state with tock Y < X will recompute it. The largest Y under the constraint will do the least amount of transition computing said value.
	\subsection{Tock Tree}
	To pair a value with it's tock concretely(I mean in the runtime, the word look bad), and to allow a value to be recomputed, we abstract over the memory space(need better words), replacing pointers to value, to tocks instead. The actual values are stored on a global data structure, the tock tree. Reading from a pointer is replaced from querying the tock tree with the tock. The tock tree additionally store machine state as they are executed, so a value might be uncomputed and recomputed in the future with any earlier machine state.
	
	The tock tree is a binary search tree with the crucial property that lookup returns the largest node with key <= the input. This allow us to drop any node in the tock tree, with the exception of the leftmost node. Each node on the tock tree, at point t, correspond to an execution of a transition, that started at tock t, and contain:
	\begin{enumerate}
		\item An array of cell(actual value), created during the transition, of corresponding tock t+1, t+2...
		\item The state it transit to.
	\end{enumerate} 
	Note that it store the transit-to state, but not the transit-from state, for that state is useless.

	Uncomputing is then merely deleting a non-leftmost value from the tock tree.

	Formally speaking, 
	\begin{mathpar}
		before: Value = P<VCell>
		
		after: Value = Tock
		
		TockTree: ???
		
		query: (TockTree, Tock) -> (Tock, Node)
		
		insert: (TockTree, Node) -> TockTree
		
		Node = ([KCell | VCell], State)
		
		before: State = Step Expr Env K | Apply K V

		after: State = Step Expr Env K Tock | Apply K V Tock
		\end{mathpar}
	\subsection{Replay}
	During execution, the tock needed to be converted back to a Cell. 
	It proceed as follow:
	\begin{enumerate}
		\item to convert tock t to a Cell:
		\item query the tock tree on t to get a Node
		\item if the cell is in the array, return said Cell
		\item otherwise, issue a replay to t.
	\end{enumerate}
	A replay t suspend the current machine state, replacing it with the State in the Node returned from tock tree, and executing until the tock reach t. The old state is then resumed with the Cell at t.
	Replay is recursive: a replay might issue lookup that require more replay.
	\begin{mathpar}
		ReplayContinuation = RK := NoReplay | RKApply V Tock RK | RKCase Tock Env N E N E K RK | RKZro Tock K RK | RKFst Tock K RK

		Replay = R := (State, RK)
		
		RApply: ((Tock, Node), RK) -> (State, RK)
		RApply((_, (cells, st)), NoReplay) = (st, NoReplay)
		RApply((t, (cells, st)), RKApply v t' rk) = if t + 1 <= t' < t + 1 + len(cells) then (Apply v cells[t' - t - 1] t', rk) else (st, RKApply v t' rk)
		RApply((t, (cells, st)), RKCase t' Env LN L RN R K RK) = if t + 1 <= t' < t + 1 + len(cells) then if cells[t' - t - 1] = VLeft X then ((Step L Env[LN := X] K, t'), rk) else if cells[t' - t - 1] = VRight Y then (Step R Env[RN := Y] K t', rk) else (st, RKCase t' Env LN L RN R K)
		RApply((t, (cells, st)), RKZro t' K) = if t + 1 <= t' < t + 1 + len(cells) then if cells[t' - t - 1] = VProd X Y then (Apply X K t', RK) else (st, RKZro t' K)
		RApply((t, (cells, st)), RKFst t' K) = if t + 1 <= t' < t + 1 + len(cells) then if cells[t' - t - 1] = VProd X Y then (Apply Y K t', RK) else (st, RKFst t' K)
	\end{mathpar}
	
	\begin{mathpar}
		FromTock: (TockTree, Tock) -> VCell | KCell | State
		From The tock tree, try to get the corresponding cell.
		If the cell is uncomputed, return the closest state that can recompute it.

		FromTock(tt, t) = 
		  let (Node cells state, nt) = query(tt, t) in
		  if nt + 1 <= t < nt + 1 + len(cells) then cells[t - nt - 1] else state

		goto: (Replay, TockTree) -> (Replay, TockTree)
		State = Step Expr Env K | Apply K V
		
		Step(N, Env, K), H goto apply(K, Env(N)), H
		
		Step(Left X, Env, K), H goto Step(X, Env, P), H' where (P, H') = Alloc(KLeft K, H)
		
		Step(Right X, Env, K), H goto Step(X, Env, P), H' where (P, H') = Alloc(KRight K, H)
		
		Step(Case X LN L RN R, Env, K), H goto Step(X, Env, P), H' where (P, H') = Alloc(KCase LN L RN R Env, H)
		
		Step(Prod L R, Env, K), H goto Step(L, Env, P), H' where (P, H') = Alloc(KProd0 K R, H)
		
		Step(Zro X, Env, K), H goto Step(X, Env, P), H' where (P, H') = Alloc(KZro K, H)
		
		Step(Fst X, Env, K), H goto Step(X, Env, P), H' where (P, H') = Alloc(KFst K, H)
		
		Step(Let A = B in C, Env, K), H goto Step(B, Env, P), H' where (P, H') = Alloc(KLet A K C Env, H)
		
		Step(App f x, Env, K), H goto Step(f, P), H' where (P, H') = Alloc(KApp0 K x, H)
		
		Step(Lam N E, Env, K), H goto Apply(K, P), H' where (P, H') = Alloc(Clos Env(fv)... N E, H)
		
		Apply(P, V) = apply(Lookup(P), V)
		apply(KLeft K, V), H goto Apply(K, P), H' where (P, H') = Alloc(VLeft V, H)
		
		apply(KRight K, V), H goto Apply(K, P), H' where (P, H') = Alloc(VRight V, H)
		
		apply(KCase Env LN L RN R K, V), H goto 
		if LookUp(V, H) = VLeft V then Step(L, Env(LN := V), K)
		= VRight V then Step(R, Env(RN := V), K)
		
		apply(KProd0 Env R K, V), H goto Step(R, Env, P), H' where (P, H') = Alloc(KProd1 V Env K, H)
		
		apply(KProd1 L K, V), H goto Apply(P, K), H' where (P, H') = Alloc(VProd L V, H)
		
		apply(KZro K, V), H goto Apply(X, K), H where VProd X Y = LookUp(V, H)
		
		apply(KFst K, V), H goto Apply(Y, K), H where VProd X Y = LookUp(V, H)
		
		apply(KLet A Env C K, B), H goto Step(C, Env(A := B), K), H
		
		apply(KApp0 Env X K, V) goto Step(X, Env, P) where (P, H'), H' = Alloc(KApp1 V K, H)
		
		apply(KApp1 F K, V), H goto Step(E, Env(N := V), K), H where (Clos Env N E) = LookUp(V, H)
	\end{mathpar}
	\section{Implementation}
	\subsection{Tock Tree}
	To exploit the temporal/spatial locality, and the 20-80 law of data access (cite?), the tock tree is implemented as a slight modification of a splay tree.

	This design grant frequently-accessed data faster access time. Crucially, consecutive insertion take amortized constant time.
	
	The tock tree is then modified such that each node contain an additional parent and child pointer. The pointers form a list, which maintain an sorted representation of the tock tree. On a query, the tock tree do a binary search to find the innermost node, then follow the parent pointer if that node is greater then the key. This process is not recursive: the parent pointer is guaranteed to have a smaller node then the input key, as binary search will yield either the exact value, or the largest value less then the input, or the smallest value greater then the input.
	\subsection{Picking Uncomputation Candidate}
	Note that the guarantee we prove is independent of our policy that decide which value to uncompute (eviction policy).
	\subsubsection{Union Find}
	\subsubsection{The Policy}
	\subsubsection{GDSF}
	\subsection{Language Implementation}
	For implementation simplicity and interoperability with other programs, zombie is implemented as a C++ library, and the Cells are ref-counted. Our evaluation compiles the program from the applicative programming language formalized above(give name), to C++ code.
	\subsection{Optimization}
	\subsubsection{Fast access path}
	Querying the tock tree for every value is slow, as it requires multiple pointer traversal.
	To combat this, each Value is a Tock paired with a weak reference, serving as a cache, to the Cell. When reading the value, if the weak reference is ok, the value is return immediately. Otherwise the default path is executed, and the weak reference is updated to point to the new Result.
	\subsubsection{Loop Unrolling}
	To avoid frequent creation of node object, and their insertion to the tock tree, multiple state transition is packed into one.
	\subsection{Bit counting}
	\section{Formal Guarantee}
	\subsection{Safety}
	Evaluating under replay semantic give same result as under normal semantic
	\subsection{Liveness}
	Evaluating will eventually produce a value
	
	Decreasing on lexicalgraphic ordering on the replay stack do work
	\subsection{Performance}
	memory consumption is linear to amount of object with O(1) access cost
	\section{Evaluation}
	%\input{intro}
	%\input{uncomputation}
	%\input{pvz}
	%\input{call_stack}
	%\input{cache}
	%\input{eval}
	%\section{Case Study(2pg)}
	%\input{related}
	%\section{Constant Optimization}
%% If your work has an appendix, this is the place to put it.
\appendix
\end{document}
\endinput
%%
%% End of file `sample-acmsmall.tex'.
